# ü§ü ISL Translator ‚Äî Indian Sign Language Real-Time Detection

[![Python](https://img.shields.io/badge/Python-3.8%2B-blue?style=flat-square&logo=python)](https://www.python.org/)
[![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange?style=flat-square&logo=tensorflow)](https://tensorflow.org/)
[![Flask](https://img.shields.io/badge/Flask-3.x-black?style=flat-square&logo=flask)](https://flask.palletsprojects.com/)
[![MediaPipe](https://img.shields.io/badge/MediaPipe-Hands-green?style=flat-square)](https://mediapipe.dev/)
[![License](https://img.shields.io/badge/License-MIT-purple?style=flat-square)](LICENSE)
[![Status](https://img.shields.io/badge/Status-Active-brightgreen?style=flat-square)]()

---

## üìñ Description

**ISL Translator** is a real-time web application that translates **Indian Sign Language (ISL)** hand gestures into text using a deep learning model trained on 42,000+ hand gesture images.

Users open the app in their browser, allow camera access, and show hand signs ‚Äî the model predicts the corresponding letter or digit **live**, accumulating signs into full words and sentences on screen.

> Indian Sign Language (ISL) is the primary sign language used by the Deaf community in India, recognised by the [Indian Sign Language Research and Training Centre (ISLRTC)](https://islrtc.nic.in/). It differs significantly from American Sign Language (ASL) and British Sign Language (BSL).

### ‚ú® Features

| Feature | Details |
|---------|---------|
| üî§ **A‚ÄìZ Alphabets** | Recognises all 26 English letters in ISL |
| üî¢ **1‚Äì9 Digits** | Recognises numeric hand signs 1 through 9 |
| üì∑ **Live Camera** | Real-time webcam inference at ~2 frames/second |
| ‚úã **Hand Tracking** | MediaPipe Hands detects and crops the hand region automatically |
| ‚è± **Hold-to-Lock** | Stable gesture for 1.5 seconds confirms the character |
| üìù **Sentence Builder** | Accumulates signs into words and sentences |
| üìä **Top-3 Predictions** | Shows confidence scores for top 3 guesses |
| üé® **Modern UI** | Dark-mode glassmorphic web interface, no install needed for users |
| üíæ **Resume Training** | Model training saves a checkpoint after every epoch and auto-resumes |

---

## üñºÔ∏è Visuals

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  üì∑  Live Camera Feed       ‚îÇ  ‚úçÔ∏è Sentence Builder       ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ  [Hand bounding box] ‚îÇ   ‚îÇ  ‚îÇ  H E L L O_          ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ  [Landmark overlay]  ‚îÇ   ‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ  ‚è± Hold Timer Ring         ‚îÇ
‚îÇ                              ‚îÇ  üìä Top Predictions        ‚îÇ
‚îÇ  Detected: A  (97.3%)       ‚îÇ   1st: A  97%             ‚îÇ
‚îÇ  ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñë‚ñë progress    ‚îÇ   2nd: 4  01%             ‚îÇ
‚îÇ                              ‚îÇ   3rd: R  01%             ‚îÇ
‚îÇ  üìù Output: HELLO_          ‚îÇ  üí° Tips                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ‚öôÔ∏è Requirements

| Requirement | Version |
|-------------|---------|
| Python | 3.8 or higher |
| TensorFlow | 2.x |
| Flask | 3.x |
| OpenCV | 4.8+ |
| NumPy | 1.24+ |
| Pillow | 10.0+ |

**Hardware:**
- Webcam (built-in or USB)
- GPU recommended for training (CPU works but is slow ~4 hours)
- Any modern browser (Chrome, Firefox, Edge) for the web app

---

## üöÄ Installation

### 1. Clone the repository

```bash
git clone https://github.com/Charliee420/SIGN-LANGUAGE.git
cd ISL-Translator
```

### 2. (Recommended) Create a virtual environment

```bash
python -m venv venv

# Windows
venv\Scripts\activate

# Linux / macOS
source venv/bin/activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Add the dataset

Download the **Indian Sign Language dataset** from Kaggle:

üîó [Indian Sign Language (ISLRTC referred)](https://www.kaggle.com/datasets/prathumarikeri/indian-sign-language-islrtc-referred)

Place the downloaded folders in the following structure:

```
ISL-Translator/
‚îî‚îÄ‚îÄ data/
    ‚îî‚îÄ‚îÄ ISL_Dataset/
        ‚îî‚îÄ‚îÄ Indian/
            ‚îú‚îÄ‚îÄ 1/        ‚Üê ~1200 images of number "1" sign
            ‚îú‚îÄ‚îÄ 2/
            ‚îú‚îÄ‚îÄ ...
            ‚îú‚îÄ‚îÄ 9/
            ‚îú‚îÄ‚îÄ A/        ‚Üê ~1200 images of letter "A" sign
            ‚îú‚îÄ‚îÄ B/
            ‚îú‚îÄ‚îÄ ...
            ‚îî‚îÄ‚îÄ Z/
```

---

## üèãÔ∏è Training the Model

```bash
python train.py
```

- Automatically resumes from the last checkpoint if interrupted
- Saves `models/isl_model.h5` when training completes
- Saves `models/checkpoint.h5` + `models/progress.json` after **every epoch**

**To start fresh (ignore previous checkpoints):**

```bash
python train.py --fresh
```

**Expected training time:**
| Hardware | Estimated Time |
|----------|---------------|
| NVIDIA GPU (CUDA) | ~20‚Äì40 minutes |
| CPU (Intel/AMD) | ~3‚Äì5 hours |

**Training progress is shown in the terminal:**

```
üöÄ Training epochs 1 ‚Üí 50  (50 remaining)
Epoch 1/50
1050/1050 ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ 46s ‚Äî loss: 0.27 ‚Äî accuracy: 0.92 ‚Äî val_accuracy: 0.99
üíæ Checkpoint saved  |  epoch 1/50  |  val_acc 99.8%
     (stop safely ‚Äî resume with:  python train.py)
```

---

## üñ•Ô∏è Usage

### Start the web app

```bash
python app.py
```

Then open your browser and go to:

```
http://localhost:5000
```

### In the browser:

1. Click **"Enable Camera"** and allow camera permission
2. Hold your hand in front of the camera
3. Show an ISL sign ‚Äî the model highlights your hand and predicts the letter
4. **Hold the sign steady for 1.5 seconds** ‚Üí letter is added to the sentence
5. Use the on-screen buttons or keyboard shortcuts to build words:

| Action | Button | Keyboard |
|--------|--------|----------|
| Add space | `‚ê£ Space` | `Space` |
| Delete last | `‚å´ Delete` | `Backspace` |
| Clear all | `üóë Clear` | `Ctrl + C` |

### Supported Signs

| Category | Signs |
|----------|-------|
| Numbers | 1 2 3 4 5 6 7 8 9 |
| Alphabets | A B C D E F G H I J K L M N O P Q R S T U V W X Y Z |

> **Note:** The digit `0` is not included as it was absent from the training dataset.

---

## üìÅ Project Structure

```
ISL-Translator/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îî‚îÄ‚îÄ ISL_Dataset/Indian/     ‚Üê Dataset (not included in repo)
‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îú‚îÄ‚îÄ isl_model.h5            ‚Üê Final trained model
‚îÇ   ‚îú‚îÄ‚îÄ checkpoint.h5           ‚Üê Per-epoch checkpoint (auto-managed)
‚îÇ   ‚îî‚îÄ‚îÄ progress.json           ‚Üê Training progress tracker
‚îú‚îÄ‚îÄ templates/
‚îÇ   ‚îî‚îÄ‚îÄ index.html              ‚Üê Web frontend (camera + UI)
‚îú‚îÄ‚îÄ app.py                      ‚Üê Flask backend + prediction API
‚îú‚îÄ‚îÄ train.py                    ‚Üê Model training script (with resume)
‚îú‚îÄ‚îÄ requirements.txt            ‚Üê Python dependencies
‚îî‚îÄ‚îÄ README.md
```

---

## üß† Model Architecture

A custom **Convolutional Neural Network (CNN)** trained from scratch:

```
Input: 64√ó64 grayscale image
  ‚îÇ
  ‚îú‚îÄ Conv2D(32) ‚Üí BN ‚Üí Conv2D(32) ‚Üí BN ‚Üí MaxPool ‚Üí Dropout(0.25)
  ‚îú‚îÄ Conv2D(64) ‚Üí BN ‚Üí Conv2D(64) ‚Üí BN ‚Üí MaxPool ‚Üí Dropout(0.25)
  ‚îú‚îÄ Conv2D(128) ‚Üí BN ‚Üí Conv2D(128) ‚Üí BN ‚Üí MaxPool ‚Üí Dropout(0.25)
  ‚îÇ
  ‚îú‚îÄ Flatten
  ‚îú‚îÄ Dense(512) ‚Üí BN ‚Üí Dropout(0.5)
  ‚îú‚îÄ Dense(256) ‚Üí BN ‚Üí Dropout(0.5)
  ‚îî‚îÄ Dense(35, softmax) ‚Üí Output
```

| Parameter | Value |
|-----------|-------|
| Input size | 64 √ó 64 √ó 1 (grayscale) |
| Total parameters | ~2.3M |
| Output classes | 35 (A‚ÄìZ + 1‚Äì9) |
| Optimiser | Adam (lr=0.001) |
| Loss | Categorical Crossentropy |
| Callbacks | EarlyStopping, ReduceLROnPlateau |

**Preprocessing pipeline (webcam ‚Üí model):**
1. Convert to grayscale
2. CLAHE contrast enhancement
3. Gaussian blur (noise reduction)
4. Otsu thresholding (binary image)
5. Resize to 64√ó64 and normalise (0‚Äì1)

---

## üõ†Ô∏è Support

If you encounter issues:

- **Camera not working** ‚Üí make sure your browser has permission (Chrome ‚Üí Settings ‚Üí Privacy ‚Üí Camera)
- **"Model not found" error** ‚Üí run `python train.py` first to generate `models/isl_model.h5`
- **Low accuracy on webcam** ‚Üí ensure good lighting, plain background, and hand clearly visible
- **Port already in use** ‚Üí change the port in `app.py`: `app.run(port=5001)`

Open an issue on GitHub or reach out via the repository's Discussions tab.

---

## üó∫Ô∏è Roadmap

### Version 1.0 (Current)
- [x] CNN model training with resume support
- [x] Flask web backend with `/predict` API
- [x] Real-time webcam detection via browser
- [x] Sentence builder with hold-to-lock
- [x] Top-3 confidence display

### Version 1.1 (Planned)
- [ ] Both-hand detection support for full ISL vocabulary
- [ ] Text-to-speech output (read the sentence aloud)
- [ ] Digit `0` support (add custom data or alternate dataset)

### Version 2.0 (Future)
- [ ] Full ISL word/phrase recognition (beyond single letters)
- [ ] Mobile-responsive PWA
- [ ] Cloud deployment (Render / Railway / Hugging Face Spaces)
- [ ] TensorFlow.js conversion for fully browser-based inference (no server needed)
- [ ] Multi-language output (Hindi, Tamil, Telugu transliteration)

---

## ü§ù Contributing

Contributions are welcome!

1. **Fork** the repository
2. Create a feature branch: `git checkout -b feature/your-feature-name`
3. Commit your changes: `git commit -m "Add: your feature description"`
4. Push to the branch: `git push origin feature/your-feature-name`
5. Open a **Pull Request**

### Development setup

```bash
git clone https://github.com/your-username/ISL-Translator.git
cd ISL-Translator
python -m venv venv && venv\Scripts\activate
pip install -r requirements.txt
```

### Code style

- Follow **PEP 8** for Python
- Keep functions small and documented
- Test with at least 3 different hand signs before submitting a PR

---

## üë• Authors & Acknowledgements

- **Dataset**: [ISLRTC Indian Sign Language Dataset](https://www.kaggle.com/datasets/prathumarikeri/indian-sign-language-islrtc-referred) by Kaggle contributor `prathumarikeri`
- **Hand Detection**: [MediaPipe Hands](https://mediapipe.dev/) by Google
- **Deep Learning Framework**: [TensorFlow / Keras](https://tensorflow.org/)
- **Backend**: [Flask](https://flask.palletsprojects.com/)

Special thanks to the **Indian Sign Language Research and Training Centre (ISLRTC)** for standardising ISL gestures that form the basis of this dataset.

---

## üìÑ License

This project is licensed under the **MIT License** ‚Äî see the [LICENSE](LICENSE) file for details.

```
MIT License ‚Äî free to use, modify, and distribute with attribution.
```

---

## üìå Project Status

> **Active Development** ‚Äî Core functionality is working. Training and accuracy improvements are ongoing. PRs and issues are welcome.

The project is being actively developed. The next major milestone is full 50-epoch training completion and both-hand ISL support.

---

<div align="center">

Made with ‚ù§Ô∏è to bridge communication for the Indian Deaf community

‚≠ê Star this repo if it helped you!

</div>
